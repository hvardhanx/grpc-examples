# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: crawl.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='crawl.proto',
  package='crawl',
  syntax='proto3',
  serialized_pb=_b('\n\x0b\x63rawl.proto\x12\x05\x63rawl\"\x19\n\tStockName\x12\x0c\n\x04name\x18\x01 \x01(\t\"\x1c\n\nStockPrice\x12\x0e\n\x06result\x18\x01 \x01(\t29\n\x05\x43rawl\x12\x30\n\x07GetData\x12\x10.crawl.StockName\x1a\x11.crawl.StockPrice\"\x00\x62\x06proto3')
)
_sym_db.RegisterFileDescriptor(DESCRIPTOR)




_STOCKNAME = _descriptor.Descriptor(
  name='StockName',
  full_name='crawl.StockName',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='name', full_name='crawl.StockName.name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=22,
  serialized_end=47,
)


_STOCKPRICE = _descriptor.Descriptor(
  name='StockPrice',
  full_name='crawl.StockPrice',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='result', full_name='crawl.StockPrice.result', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=49,
  serialized_end=77,
)

DESCRIPTOR.message_types_by_name['StockName'] = _STOCKNAME
DESCRIPTOR.message_types_by_name['StockPrice'] = _STOCKPRICE

StockName = _reflection.GeneratedProtocolMessageType('StockName', (_message.Message,), dict(
  DESCRIPTOR = _STOCKNAME,
  __module__ = 'crawl_pb2'
  # @@protoc_insertion_point(class_scope:crawl.StockName)
  ))
_sym_db.RegisterMessage(StockName)

StockPrice = _reflection.GeneratedProtocolMessageType('StockPrice', (_message.Message,), dict(
  DESCRIPTOR = _STOCKPRICE,
  __module__ = 'crawl_pb2'
  # @@protoc_insertion_point(class_scope:crawl.StockPrice)
  ))
_sym_db.RegisterMessage(StockPrice)


import abc
from grpc.beta import implementations as beta_implementations
from grpc.framework.common import cardinality
from grpc.framework.interfaces.face import utilities as face_utilities

class BetaCrawlServicer(object):
  """<fill me in later!>"""
  __metaclass__ = abc.ABCMeta
  @abc.abstractmethod
  def GetData(self, request, context):
    raise NotImplementedError()

class BetaCrawlStub(object):
  """The interface to which stubs will conform."""
  __metaclass__ = abc.ABCMeta
  @abc.abstractmethod
  def GetData(self, request, timeout):
    raise NotImplementedError()
  GetData.future = None

def beta_create_Crawl_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
  import crawl_pb2
  import crawl_pb2
  request_deserializers = {
    ('crawl.Crawl', 'GetData'): crawl_pb2.StockName.FromString,
  }
  response_serializers = {
    ('crawl.Crawl', 'GetData'): crawl_pb2.StockPrice.SerializeToString,
  }
  method_implementations = {
    ('crawl.Crawl', 'GetData'): face_utilities.unary_unary_inline(servicer.GetData),
  }
  server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
  return beta_implementations.server(method_implementations, options=server_options)

def beta_create_Crawl_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
  import crawl_pb2
  import crawl_pb2
  request_serializers = {
    ('crawl.Crawl', 'GetData'): crawl_pb2.StockName.SerializeToString,
  }
  response_deserializers = {
    ('crawl.Crawl', 'GetData'): crawl_pb2.StockPrice.FromString,
  }
  cardinalities = {
    'GetData': cardinality.Cardinality.UNARY_UNARY,
  }
  stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
  return beta_implementations.dynamic_stub(channel, 'crawl.Crawl', cardinalities, options=stub_options)
# @@protoc_insertion_point(module_scope)
